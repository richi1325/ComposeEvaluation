{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:32:36.618035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-06 19:32:36.618053: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from music21 import instrument, note, stream, chord, duration\n",
    "from models.RNNAttention import create_network, sample_with_temp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "BASE_DIR = os.getcwd()\n",
    "music_name = 'classical'\n",
    "run_folder = os.path.join(BASE_DIR,\"output\",music_name)\n",
    "\n",
    "# model params\n",
    "embed_size = 100\n",
    "rnn_units = 256\n",
    "use_attention = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_folder = os.path.join(run_folder, 'store')\n",
    "\n",
    "with open(os.path.join(store_folder, 'distincts'), 'rb') as filepath:\n",
    "    distincts = pkl.load(filepath)\n",
    "    note_names, n_notes, duration_names, n_durations = distincts\n",
    "\n",
    "with open(os.path.join(store_folder, 'lookups'), 'rb') as filepath:\n",
    "    lookups = pkl.load(filepath)\n",
    "    note_to_int, int_to_note, duration_to_int, int_to_duration = lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:32:41.898032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-06 19:32:41.898050: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-06 19:32:41.898064: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a0da3121b20d): /proc/driver/nvidia/version does not exist\n",
      "2021-12-06 19:32:41.898172: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "weights_file = \"weights-improvement-372-9.3068-bigger.h5\"\n",
    "model, att_model = create_network(n_notes, n_durations, embed_size, rnn_units, use_attention)\n",
    "\n",
    "weight_source = os.path.join(weights_folder,weights_file)\n",
    "model.load_weights(weight_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:32:45.952798: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-06 19:32:45.972407: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4fd3888d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4fd2f4eaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---------------------------------------- 1 ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "notes_temp = 0.75\n",
    "duration_temp = 0.25\n",
    "max_extra_notes = 120\n",
    "max_seq_len = 128\n",
    "seq_len = 16\n",
    "\n",
    "notes_random = []\n",
    "for letters in [\"A\",\"C\",\"D\",\"E\",\"F\",\"F#\",\"G\",\"G#\"]:\n",
    "    for number in range(2,8):\n",
    "        notes_random.append(letters+str(number))\n",
    "\n",
    "durations_random = [0,0.25,0.5,0.75,1,1.25,1.5,1.75,2]\n",
    "sequence_length = len(notes_random)\n",
    "i=1\n",
    "while True:\n",
    "    try:\n",
    "        notes = ['C2', 'A6', 'E6', 'F#4', 'A5', 'F5', 'G#3', 'F#3', 'F6', 'D6', 'D5', 'F#5', 'G#2', 'F5', 'F#2', 'E6', 'E3', 'G3', 'C5', 'C5', 'D4', 'F#5', 'C7', 'F#3', 'G2', 'F4', 'F#3', 'D3', 'G#2', 'C5', 'A5', 'E2']\n",
    "        durations = [1.5, 0.25, 0.5, 1, 0.75, 1.25, 1.5, 1.5, 0.75, 1.25, 0.5, 1.75, 0, 1, 0.25, 1.5, 1.25, 0.75, 1, 1.25, 0.5, 0.25, 1.25, 0.25, 1, 0.5, 1.25, 1, 1.75, 0.25, 1.25, 1.5]\n",
    "        prediction_output = []\n",
    "        notes_input_sequence = []\n",
    "        durations_input_sequence = []\n",
    "\n",
    "        overall_preds = []\n",
    "\n",
    "        for n, d in zip(notes,durations):\n",
    "            note_int = note_to_int[n]\n",
    "            duration_int = duration_to_int[d]\n",
    "\n",
    "            notes_input_sequence.append(note_int)\n",
    "            durations_input_sequence.append(duration_int)\n",
    "\n",
    "            prediction_output.append([n, d])\n",
    "\n",
    "            if n != 'START':\n",
    "                midi_note = note.Note(n)\n",
    "\n",
    "                new_note = np.zeros(128)\n",
    "                new_note[midi_note.pitch.midi] = 1\n",
    "                overall_preds.append(new_note)\n",
    "\n",
    "\n",
    "        att_matrix = np.zeros(shape = (max_extra_notes+sequence_length, max_extra_notes))\n",
    "\n",
    "        for note_index in range(max_extra_notes):\n",
    "            prediction_input = [\n",
    "                np.array([notes_input_sequence])\n",
    "                , np.array([durations_input_sequence])\n",
    "               ]\n",
    "\n",
    "            notes_prediction, durations_prediction = model.predict(prediction_input, verbose=0)\n",
    "            if use_attention:\n",
    "                att_prediction = att_model.predict(prediction_input, verbose=0)[0]\n",
    "                att_matrix[(note_index-len(att_prediction)+sequence_length):(note_index+sequence_length), note_index] = att_prediction\n",
    "\n",
    "            new_note = np.zeros(128)\n",
    "\n",
    "            for idx, n_i in enumerate(notes_prediction[0]):\n",
    "                try:\n",
    "                    note_name = int_to_note[idx]\n",
    "                    midi_note = note.Note(note_name)\n",
    "                    new_note[midi_note.pitch.midi] = n_i\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            overall_preds.append(new_note)\n",
    "\n",
    "\n",
    "            i1 = sample_with_temp(notes_prediction[0], notes_temp)\n",
    "            i2 = sample_with_temp(durations_prediction[0], duration_temp)\n",
    "\n",
    "\n",
    "            note_result = int_to_note[i1]\n",
    "            duration_result = int_to_duration[i2]\n",
    "\n",
    "            prediction_output.append([note_result, duration_result])\n",
    "\n",
    "            notes_input_sequence.append(i1)\n",
    "            durations_input_sequence.append(i2)\n",
    "\n",
    "            if len(notes_input_sequence) > max_seq_len:\n",
    "                notes_input_sequence = notes_input_sequence[1:]\n",
    "                durations_input_sequence = durations_input_sequence[1:]\n",
    "            if note_result == 'START':\n",
    "                break\n",
    "        overall_preds = np.transpose(np.array(overall_preds)) \n",
    "\n",
    "        output_folder = os.path.join(run_folder, 'output')\n",
    "\n",
    "        midi_stream = stream.Stream()\n",
    "\n",
    "        for pattern in prediction_output:\n",
    "            note_pattern, duration_pattern = pattern\n",
    "            if ('.' in note_pattern):\n",
    "                notes_in_chord = note_pattern.split('.')\n",
    "                chord_notes = []\n",
    "                for current_note in notes_in_chord:\n",
    "                    new_note = note.Note(current_note)\n",
    "                    new_note.duration = duration.Duration(duration_pattern)\n",
    "                    new_note.storedInstrument = instrument.Violoncello()\n",
    "                    chord_notes.append(new_note)\n",
    "                new_chord = chord.Chord(chord_notes)\n",
    "                midi_stream.append(new_chord)\n",
    "            elif note_pattern == 'rest':\n",
    "                new_note = note.Rest()\n",
    "                new_note.duration = duration.Duration(duration_pattern)\n",
    "                new_note.storedInstrument = instrument.Violoncello()\n",
    "                midi_stream.append(new_note)\n",
    "            elif note_pattern != 'START':\n",
    "                new_note = note.Note(note_pattern)\n",
    "                new_note.duration = duration.Duration(duration_pattern)\n",
    "                new_note.storedInstrument = instrument.Violoncello()\n",
    "                midi_stream.append(new_note)\n",
    "        midi_stream = midi_stream.chordify()\n",
    "        midi_stream.write('midi', fp=os.path.join(output_folder, f'exp372_{i}.mid'))\n",
    "        print(\"-\"*40,f\"{i}\",\"-\"*40)\n",
    "        if i==1:\n",
    "            break\n",
    "        i+=1\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6008e1063d367d629343e527dcc17ff52fa6e8616b8edc82981e2ae3282b9da9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
