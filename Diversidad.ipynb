{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce79f7-9257-4ded-a7ce-61a927d71dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, corpus, instrument, midi, note, chord, pitch\n",
    "import os\n",
    "import seaborn as snb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677c315-271c-4f07-a7b9-c55a53a5282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_midi(midi_path, remove_drums):\n",
    "    # There is an one-line method to read MIDIs\n",
    "    # but to remove the drums we need to manipulate some\n",
    "    # low level MIDI events.\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(midi_path)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    if (remove_drums):\n",
    "        for i in range(len(mf.tracks)):\n",
    "            mf.tracks[i].events = [ev for ev in mf.tracks[i].events if ev.channel != 10]          \n",
    "\n",
    "    return midi.translate.midiFileToStream(mf)\n",
    "\n",
    "def concat_path(path, child):\n",
    "    return path + \"/\" + child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9952000-df23-4186-b6f9-3453b8908127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import roman\n",
    "\n",
    "def note_count(measure, count_dict):\n",
    "    bass_note = None\n",
    "    for chord in measure.recurse().getElementsByClass('Chord'):\n",
    "        # All notes have the same length of its chord parent.\n",
    "        note_length = chord.quarterLength\n",
    "        for note in chord.pitches:          \n",
    "            # If note is \"C5\", note.name is \"C\". We use \"C5\"\n",
    "            # style to be able to detect more precise inversions.\n",
    "            note_name = str(note) \n",
    "            if (bass_note is None or bass_note.ps > note.ps):\n",
    "                bass_note = note\n",
    "                \n",
    "            if note_name in count_dict:\n",
    "                count_dict[note_name] += note_length\n",
    "            else:\n",
    "                count_dict[note_name] = note_length\n",
    "        \n",
    "    return bass_note\n",
    "                \n",
    "def simplify_roman_name(roman_numeral):\n",
    "    # Chords can get nasty names as \"bII#86#6#5\",\n",
    "    # in this method we try to simplify names, even if it ends in\n",
    "    # a different chord to reduce the chord vocabulary and display\n",
    "    # chord function clearer.\n",
    "    ret = roman_numeral.romanNumeral\n",
    "    inversion_name = None\n",
    "    inversion = roman_numeral.inversion()\n",
    "    \n",
    "    # Checking valid inversions.\n",
    "    if ((roman_numeral.isTriad() and inversion < 3) or\n",
    "            (inversion < 4 and\n",
    "                 (roman_numeral.seventh is not None or roman_numeral.isSeventh()))):\n",
    "        inversion_name = roman_numeral.inversionName()\n",
    "        \n",
    "    if (inversion_name is not None):\n",
    "        ret = ret + str(inversion_name)\n",
    "        \n",
    "    elif (roman_numeral.isDominantSeventh()): ret = ret + \"M7\"\n",
    "    elif (roman_numeral.isDiminishedSeventh()): ret = ret + \"o7\"\n",
    "    return ret\n",
    "                \n",
    "def harmonic_reduction(midi_file):\n",
    "    ret = []\n",
    "    temp_midi = stream.Score()\n",
    "    temp_midi_chords = midi_file.chordify()\n",
    "    temp_midi.insert(0, temp_midi_chords)    \n",
    "    music_key = temp_midi.analyze('key')\n",
    "    max_notes_per_chord = 4   \n",
    "    for m in temp_midi_chords.measures(0, None): # None = get all measures.\n",
    "        if (type(m) != stream.Measure):\n",
    "            continue\n",
    "        \n",
    "        # Here we count all notes length in each measure,\n",
    "        # get the most frequent ones and try to create a chord with them.\n",
    "        count_dict = dict()\n",
    "        bass_note = note_count(m, count_dict)\n",
    "        if (len(count_dict) < 1):\n",
    "            ret.append(\"-\") # Empty measure\n",
    "            continue\n",
    "        \n",
    "        sorted_items = sorted(count_dict.items(), key=lambda x:x[1])\n",
    "        sorted_notes = [item[0] for item in sorted_items[-max_notes_per_chord:]]\n",
    "        measure_chord = chord.Chord(sorted_notes)\n",
    "        \n",
    "        # Convert the chord to the functional roman representation\n",
    "        # to make its information independent of the music key.\n",
    "        roman_numeral = roman.romanNumeralFromChord(measure_chord, music_key)\n",
    "        ret.append(simplify_roman_name(roman_numeral))\n",
    "        \n",
    "    return ret\n",
    "\n",
    "#harmonic_reduction(base_midi)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb69a823-279e-4a4f-953e-25856155660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba05e4-464a-419a-b78e-34bf65270beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./output/classical_150_it_100_songs/store/train.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data = [f'./data/classical/{j}' for j in f.read().split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8ac2e-62c3-4855-878a-4b60982d42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_games = data[0:80]\n",
    "df_array = []\n",
    "for i in target_games:\n",
    "    elemento = open_midi(i,True)\n",
    "    df_array.append({'midi_name':os.path.basename(i),'coef':float(elemento.analyze('key').correlationCoefficient), 'key_signature': str(elemento.analyze('key')),'harmonic_reduction':harmonic_reduction(elemento)})\n",
    "sonic_df = pd.DataFrame(df_array)\n",
    "sonic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981894c6-3b6d-4c1b-bff5-46d054dc4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "model = gensim.models.Word2Vec(sonic_df[\"harmonic_reduction\"], min_count=2, window=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12c8bb-10b6-402d-8116-35a17ef0c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonic_df [\"name\"] = [f\"a_{i}\" for i in range(0,80)]\n",
    "sonic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcf836-4098-49c6-9300-15108a46a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_harmony(model, harmonic_reduction):\n",
    "    # Gets the model vector values for each chord from the reduction.\n",
    "    word_vecs = []\n",
    "    for word in harmonic_reduction:\n",
    "        try:\n",
    "            vec = model[word]\n",
    "            word_vecs.append(vec)\n",
    "        except KeyError:\n",
    "            # Ignore, if the word doesn't exist in the vocabulary\n",
    "            pass\n",
    "    \n",
    "    # Assuming that document vector is the mean of all the word vectors.\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "def cosine_similarity(vecA, vecB):\n",
    "    # Find the similarity between two vectors based on the dot product.\n",
    "    csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "    if np.isnan(np.sum(csim)):\n",
    "        return 0\n",
    "    \n",
    "    return csim\n",
    "\n",
    "def calculate_similarity_aux(df, model, source_name, target_names=[], threshold=0):\n",
    "    source_harmo = df[df[\"name\"] == source_name][\"harmonic_reduction\"].values[0]\n",
    "    source_vec = vectorize_harmony(model, source_harmo)    \n",
    "    results = []\n",
    "    for name in target_names:\n",
    "        target_harmo = df[df[\"name\"] == name][\"harmonic_reduction\"].values[0]\n",
    "        if (len(target_harmo) == 0):\n",
    "            continue\n",
    "            \n",
    "        target_vec = vectorize_harmony(model, target_harmo)       \n",
    "        sim_score = cosine_similarity(source_vec, target_vec)\n",
    "        if sim_score > threshold:\n",
    "            results.append({\n",
    "                'score' : sim_score,\n",
    "                'name' : name\n",
    "            })\n",
    "                \n",
    "    # Sort results by score in desc order\n",
    "    results.sort(key=lambda k : k['score'] , reverse=True)\n",
    "    return results\n",
    "\n",
    "def calculate_similarity(df, model, source_name, target_prefix, threshold=0):\n",
    "    source_midi_names = df[df[\"name\"] == source_name][\"name\"].values\n",
    "    if (len(source_midi_names) == 0):\n",
    "        print(\"Invalid source name\")\n",
    "        return\n",
    "    \n",
    "    source_midi_name = source_midi_names[0]\n",
    "    \n",
    "    target_midi_names = df[df[\"name\"].str.startswith(target_prefix)][\"name\"].values  \n",
    "    if (len(target_midi_names) == 0):\n",
    "        print(\"Invalid target prefix\")\n",
    "        return\n",
    "    \n",
    "    return calculate_similarity_aux(df, model, source_midi_name, target_midi_names, threshold)\n",
    "\n",
    "data = []\n",
    "index = []\n",
    "for elemento in sonic_df[\"name\"]:\n",
    "    index.append(elemento)\n",
    "    data.append(np.array([j[\"score\"] for j in calculate_similarity(sonic_df, model, elemento, \"a\")]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fd7ca-656c-47a9-b705-255e61163499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metricsGAN import get_polyphony_score, get_midi_pattern, get_tones\n",
    "\n",
    "def info_tones(midi_pattern):\n",
    "  tones = get_tones(midi_pattern)\n",
    "  stats = {}\n",
    "  stats['num_tones'] = len(tones)\n",
    "  stats['tone_min'] = min(tones)\n",
    "  stats['tone_max'] = max(tones)\n",
    "  stats['tone_span'] = max(tones)-min(tones)\n",
    "  stats['tones_unique'] = len(set(tones))\n",
    "  return stats\n",
    "\n",
    "poly_score = [get_polyphony_score(get_midi_pattern(file)) for file in target_games]\n",
    "tones_music = [info_tones(get_midi_pattern(file)) for file in target_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91e342-4bb2-4646-8dfe-2d910920d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(sonic_df[\"midi_name\"],data,poly_score)),columns=[\"music\",\"similitud\",\"polifonia\"]).set_index(\"music\")\n",
    "df2 = pd.DataFrame(tones_music,index=sonic_df[\"midi_name\"])\n",
    "df = pd.merge(df,df2,how='outer',left_index=True,right_index=True)\n",
    "del df2\n",
    "df[\"resultado\"] = (df[\"similitud\"]/df[\"polifonia\"])*(df[\"tone_span\"]/df[\"tones_unique\"])\n",
    "df = pd.merge(df,sonic_df.set_index(\"midi_name\")[\"key_signature\"],how='outer',left_index=True,right_index=True)\n",
    "df = df.sort_values(by=['resultado'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06592f-e421-474d-90c7-dc9bf4bb2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"resultado2\"] = df[\"similitud\"]*sonic_df.set_index(df.index)[\"coef\"] +df[\"polifonia\"]*(df[\"tone_span\"]/df[\"tone_span\"].max())\n",
    "df = df.sort_values(by=['resultado2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f89c2f-e924-4211-9dc2-ff3fa5c827fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = df[[\"polifonia\"]]\n",
    "plotdf = pd.merge(plotdf,sonic_df.set_index(df.index)[\"coef\"],how=\"inner\",right_index=True,left_index=True)\n",
    "plotdf = plotdf.reset_index()\n",
    "plotdf[\"consistencia de escala\"] = plotdf[\"coef\"]\n",
    "del plotdf[\"coef\"]\n",
    "del plotdf[\"index\"]\n",
    "plotdf = plotdf.sort_values(by=[\"polifonia\"])\n",
    "#plotdf[\"tone_span\"] = df[\"tone_span\"]/df[\"tone_span\"].max()\n",
    "#plotdf = plotdf.sort_values(by=['tone_span'])\n",
    "plt.figure(figsize=(17,10))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.lineplot(data=plotdf, palette=\"tab10\", markers = True, linewidth=2.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
